{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://gitlab.eumetsat.int/eumetlab/oceans/ocean-training/tools/frameworks/-/raw/main/img/Standard_banner.png' align='right' width='100%'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"../Index.ipynb\" target=\"_blank\"><< Index</a>\n",
    "<br>\n",
    "<a href=\"./2_1_OLCI_advanced_data_access_eumdac.ipynb\" target=\"_blank\"><< Advanced OLCI data access with the EUMDAC client</a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a href=\"./2_3_OLCI_SNAP_batch_processing_C2RCC.ipynb\" target=\"_blank\">Using SNAP to batch process OLCI with C2RCC >></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"#138D75\">**Copernicus Marine Training Service**</font> <br>\n",
    "**Copyright:** 2023 EUMETSAT <br>\n",
    "**License:** MIT <br>\n",
    "**Authors:** Ben Loveday (EUMETSAT/Innoflair UG), Hayley Evers-King (EUMETSAT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<html>\n",
    "  <div style=\"width:100%\">\n",
    "    <div style=\"float:left\"><a href=\"https://mybinder.org/v2/git/https%3A%2F%2Fgitlab.eumetsat.int%2Feumetlab%2Foceans%2Focean-training%2Fsensors%2Flearn-olci/HEAD?urlpath=%2Ftree%2F2_OLCI_advanced%2F2_2_acquire_OLCI_time_series.ipynb\"><img src=\"https://mybinder.org/badge_logo.svg\" alt=\"Open in Binder\"></a></div>\n",
    "    <div style=\"float:left\"><p>&emsp;</p></div>\n",
    "  </div>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<h3>Learn OLCI: Advanced</h3></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    \n",
    "<b>PREREQUISITES </b>\n",
    "    \n",
    "Users should review the following notebooks for more information on setting up a credentials files for using the eumdac python library to retrieve OLCI data from the Data Store:\n",
    "    \n",
    "- **<a href=\"../1_OLCI_introductory/1_1a_OLCI_data_access_Data_Store.ipynb\">1_1a_OLCI_data_access_Data_Store.ipynb</a>**\n",
    "\n",
    "You will also need to have registered for a **<a href=\"https://eoportal.eumetsat.int/\" target=\"_blank\">A EUMETSAT Earth Observation Portal account</a>** to download from the EUMETSAT Data Store.\n",
    "\n",
    "</div>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2 Acquiring a regional OLCI times series\n",
    "\n",
    "### Data used\n",
    "\n",
    "| Product Description | Data Store collection ID| Product Navigator |\n",
    "|:--------------------:|:-----------------------:|:-------------:|\n",
    "| Sentinel-3 OLCI level-1B full resolution | EO:EUM:DAT:0409 | <a href=\"https://navigator.eumetsat.int/product/EO:EUM:DAT:SENTINEL-3:OL_1_EFR___NTC?query=OLCI&filter=satellite__Sentinel-3&filter=instrument__OLCI&filter=processingLevel__Level%201%20Data&s=advanced\" target=\"_blank\">link</a> |\n",
    "| Sentinel-3 OLCI level-2 full resolution | EO:EUM:DAT:0407 | <a href=\"https://navigator.eumetsat.int/product/EO:EUM:DAT:SENTINEL-3:OL_2_WFR___NTC?query=OLCI&filter=satellite__Sentinel-3&filter=instrument__OLCI&filter=processingLevel__Level%202%20Data&s=advanced\" target=\"_blank\">link</a> |\n",
    "\n",
    "### Learning outcomes\n",
    "\n",
    "At the end of this notebook you will know;\n",
    "* <font color=\"#138D75\">**Search**</font> for a time series of OLCI data (L1B or L2) for your region of interest using the EUMETSAT Data Store API client (`eumdac`)\n",
    "* <font color=\"#138D75\">**Download**</font> this time series\n",
    "\n",
    "### Outline\n",
    "\n",
    "The EUMETSAT Data Store offers many ways to interact with data in order to refine searches. Many of these methods are supported by the EUMETSAT Data Access Client (`eumdac`). In this notebook we will showcase some of the possibilities for using `eumdac` to better interact with OLCI collections. This notebook assumes that you already have an understanding of the available Data Store interfaces, which you can gain by running the **<a href=\"../1_OLCI_introductory/1_1a_OLCI_data_access_Data_Store.ipynb\">1_1a_OLCI_data_access_Data_Store</a>** notebook.\n",
    "\n",
    "\n",
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "\n",
    "## <a id='TOC_TOP'></a>Contents\n",
    "\n",
    "</div>\n",
    "    \n",
    "1. [Step 1: Authenticating the API](#section1)\n",
    "1. [Step 2: Creating a search by collection](#section2)\n",
    "1. [Step 3: Filtering by time](#section3)\n",
    "1. [Step 4: Filtering by space](#section4)\n",
    "1. [Step 5: Filtering by timeliness](#section5)\n",
    "1. [Step 6: Filtering by satellite](#section6)\n",
    "1. [Step 7: Removing NTC duplicates](#section7)\n",
    "1. [Step 8: Downloading, filtering by polygon overlap](#section8)\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we use Python, we nearly always start by importing the libraries we need. Each library gives us access to the capabilities we need to perform specific tasks. We can import library as shown in the box below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime     # a libary that allows us to work with dates and times\n",
    "import json         # a library that helps us make JSON format files\n",
    "import numpy as np  # a library that lets us work with arrays; we import this with a new name \"np\"\n",
    "import os           # a library that allows us access to basic operating system commands like making directories\n",
    "from shapely import geometry # a library that support construction of geometry objects\n",
    "import shutil       # a library that allows us access to basic operating system commands like copy\n",
    "import xml.etree.ElementTree as ET # a library that allows us to work with XML files\n",
    "import zipfile      # a library that allows us to unzip zip-files.\n",
    "import eumdac       # a tool that helps us download via the eumetsat/data-store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will create a download directory to store the products we will download in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_dir = os.path.join(os.getcwd(), \"products\")\n",
    "os.makedirs(download_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "\n",
    "## <a id='section1'></a>Step 1: Authenticating the API\n",
    "[Back to top](#TOC_TOP)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we use the Data Store to download data, we must first authenticate our access and retrieve an access token. More **essential** information on setting this up can be found in the **<a href=\"../1_OLCI_introductory/1_1a_OLCI_data_access_Data_Store.ipynb\">1_1a_OLCI_data_access_Data_Store</a>** notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This token '9eb7d22d-311f-3239-927b-2766c192f2e6' expires 2022-07-18 09:49:13.412403\n"
     ]
    }
   ],
   "source": [
    "# load credentials\n",
    "with open(os.path.join(os.path.expanduser(\"~\"),'.eumdac_credentials')) as json_file:\n",
    "    credentials = json.load(json_file)\n",
    "    token = eumdac.AccessToken((credentials['consumer_key'], credentials['consumer_secret']))\n",
    "    print(f\"This token '{token}' expires {token.expiration}\")\n",
    "\n",
    "# create data store object\n",
    "datastore = eumdac.DataStore(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "\n",
    "## <a id='section2'></a>Step 2: Creating a search by collection\n",
    "[Back to top](#TOC_TOP)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will work with the OLCI Level-1 full resolution data throughout this notebook. The collection ID for this data type is `EO:EUM:DAT:0409`. You can find this information on the Data Store (https://data.eumetsat.int/), or ask the `eumdac` client to tell you all the avaiable collections by calling the `eumdac.DataStore(token).collections` method.\n",
    "\n",
    "First, we need to define our **collection ID**;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set collection ID for OLCI L1 EFR\n",
    "collectionID = 'EO:EUM:DAT:0409'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To filter by collection, we simply provide the collectionID to the `datastore.get_collection method`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OLCI Level 1B Full Resolution - Sentinel-3\n",
      "---\n",
      "OLCI (Ocean and Land Colour Instrument) Full resolution: 300m at nadir. Level 1 products are calibrated Top Of Atmosphere radiance values at OLCI 21 spectral bands. Radiances are computed from the instrument digital counts by applying geo-referencing, radiometric processing (non-linearity correction, smear correction, dark offset correction, absolute gain calibration adjusted for gain evolution with time), and stray-light correction for straylight effects in OLCI camera's spectrometer and ground imager. Additionally, spatial resampling of OLCI pixels to the 'ideal' instrument grid, initial pixel classification, and annotation at tie points with auxiliary meteorological data and acquisition geometry are provided. The radiance products are accompanied by error estimate products, however the error values are currently not available. - All Sentinel-3 NRT products are available at pick-up point in less than 3h. - All Sentinel-3 Non Time Critical (NTC) products are available at pick-up point in less than 30 days. Sentinel-3 is part of a series of Sentinel satellites, under the umbrella of the EU Copernicus programme.\n"
     ]
    }
   ],
   "source": [
    "# Use collection ID\n",
    "selected_collection = datastore.get_collection(collectionID)\n",
    "print(f\"{selected_collection.title}\\n---\\n{selected_collection.abstract}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "\n",
    "## <a id='section3'></a>Step 3: Filtering by time\n",
    "[Back to top](#TOC_TOP)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To filter by time, we can pass python *datetime* arguments to the **dtstart** and **dtend** arguments of our collection when using the `.search()` method. We construct these as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time filter the collection for products\n",
    "dtstart = datetime.datetime(2022, 6, 24, 0, 0)\n",
    "dtend = datetime.datetime(2022, 6, 28, 23, 59)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets apply these date/time bounds to our search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4590 products\n"
     ]
    }
   ],
   "source": [
    "products = selected_collection.search(dtstart=dtstart, dtend=dtend)\n",
    "print(f\"Found {len(products)} products\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note: can can see a full range of the search options available in a collection object by using the `selected_collection.search_options` method*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "\n",
    "## <a id='section4'></a>Step 4: Filtering by space\n",
    "[Back to top](#TOC_TOP)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also add geographical filtering by passing in a <a href=\"https://en.wikipedia.org/wiki/Well-known_text_representation_of_geometry\" target=\"_blank\">Well Known Text</a> (WKT) format region of interest into the **geo** argument of the `.search()` method. The box below defines our WKT using the `shapely` geometry library, which is useful as it gives us a polygon object that we later use to compare our ROI area with the granules we are looking at."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# space/time filter the collection for products\n",
    "north = 58.50\n",
    "south = 53.75\n",
    "east = 21.80\n",
    "west = 17.50\n",
    "ROI = [[west, south], [east, south], [east, north], [west, north], [west, south]]\n",
    "ROI_WKT = geometry.Polygon([[p[0], p[1]] for p in ROI])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets use this polygon to refine our search further..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25 products\n"
     ]
    }
   ],
   "source": [
    "products = selected_collection.search(\n",
    "    geo=ROI_WKT,\n",
    "    dtstart=dtstart, \n",
    "    dtend=dtend)\n",
    "print(f\"Found {len(products)} products\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "\n",
    "## <a id='section5'></a>Step 5: Filtering by timeliness\n",
    "[Back to top](#TOC_TOP)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this instance, we are only interested in Non Time-Critical (NTC) OLCI products. As before, we can add this filter to our search as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 13 products\n"
     ]
    }
   ],
   "source": [
    "products = selected_collection.search(\n",
    "    geo=ROI_WKT,\n",
    "    dtstart=dtstart, \n",
    "    dtend=dtend, \n",
    "    timeliness='NT')\n",
    "print(f\"Found {len(products)} products\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "\n",
    "## <a id='section6'></a>Step 6: Filtering by satellite\n",
    "[Back to top](#TOC_TOP)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, in this instance, we are only interested in products from Sentinel-3A, so we can prune our list further using the `sat` option in our filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6 products\n"
     ]
    }
   ],
   "source": [
    "products = selected_collection.search(\n",
    "    geo=ROI_WKT,\n",
    "    dtstart=dtstart, \n",
    "    dtend=dtend, \n",
    "    timeliness='NT',\n",
    "    sat=\"Sentinel-3A\")\n",
    "print(f\"Found {len(products)} products\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "\n",
    "## <a id='section7'></a>Step 7: Removing NTC duplicates\n",
    "[Back to top](#TOC_TOP)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes, during NTC processing, we have to revisit some granules to process them further. This is typically due to instances where we have to wait for more ancillary data. In this case, two NTC products are available on the Data Store. We only want the final product, which always has a later time. The box below will filter for the latest file only, taking advantage of the Data Stores default to show most recent products first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5 products\n"
     ]
    }
   ],
   "source": [
    "processed_list = []\n",
    "final_products = []\n",
    "for product in products:\n",
    "    file_tags = str(product).split('_')\n",
    "    file_tags = [i for i in file_tags if i]\n",
    "    granule_start = file_tags[4]\n",
    "    if granule_start not in processed_list:\n",
    "        final_products.append(product)\n",
    "        processed_list.append(granule_start)\n",
    "        \n",
    "print(f\"Found {len(final_products)} products\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "\n",
    "## <a id='section8'></a>Step 8: Downloading, filtering by polygon overlap\n",
    "[Back to top](#TOC_TOP)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now narrowed our search to a small number of polygons, but some of them may only slightly intersect with our region of interest. We can filter by percentage overlap by pre-checking the manifest file, and discarding the granules that don't meet a required overlap threshold. We will set this at 25%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap_threshold = 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have defined our overlap we can download the data. The box below will do this, but requires some explanation.\n",
    "\n",
    "* Firstly, in the first line, we set up a loop to iterate over each of our products of interest.\n",
    "* Secondly, we read **only** the XML manifest file from each product. This manifest contains the footprint of the product, which we can compare with the ROI we defined above, calculating the percentage overlap between the two **pc_overlap**\n",
    "* Thirdly, if the overlap percentage is greater than our threshold, we download the product by reading it into our download directory. The product arrives as a zip file, so we also unzip it and then clean up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage overlap: 100%, downloading product\n",
      "Downloading S3A_OL_1_EFR____20220628T085911_20220628T090211_20220629T160353_0180_087_050_1980_MAR_O_NT_002.SEN3.zip.\n",
      "Download of product S3A_OL_1_EFR____20220628T085911_20220628T090211_20220629T160353_0180_087_050_1980_MAR_O_NT_002.SEN3.zip finished.\n",
      "Unzipping of product /Users/benloveday/Code/Git_Reps/CMTS/internal/sensors/learn-olci/2_OLCI_advanced/products/S3A_OL_1_EFR____20220628T085911_20220628T090211_20220629T160353_0180_087_050_1980_MAR_O_NT_002.SEN3.zip finished.\n",
      "Percentage overlap: 100%, downloading product\n",
      "Downloading S3A_OL_1_EFR____20220627T092522_20220627T092822_20220630T140909_0179_087_036_1980_MAR_O_NT_002.SEN3.zip.\n",
      "Download of product S3A_OL_1_EFR____20220627T092522_20220627T092822_20220630T140909_0179_087_036_1980_MAR_O_NT_002.SEN3.zip finished.\n",
      "Unzipping of product /Users/benloveday/Code/Git_Reps/CMTS/internal/sensors/learn-olci/2_OLCI_advanced/products/S3A_OL_1_EFR____20220627T092522_20220627T092822_20220630T140909_0179_087_036_1980_MAR_O_NT_002.SEN3.zip finished.\n",
      "Percentage overlap: 71%, downloading product\n",
      "Downloading S3A_OL_1_EFR____20220626T095133_20220626T095433_20220627T152906_0179_087_022_1980_MAR_O_NT_002.SEN3.zip.\n",
      "Download of product S3A_OL_1_EFR____20220626T095133_20220626T095433_20220627T152906_0179_087_022_1980_MAR_O_NT_002.SEN3.zip finished.\n",
      "Unzipping of product /Users/benloveday/Code/Git_Reps/CMTS/internal/sensors/learn-olci/2_OLCI_advanced/products/S3A_OL_1_EFR____20220626T095133_20220626T095433_20220627T152906_0179_087_022_1980_MAR_O_NT_002.SEN3.zip finished.\n",
      "Percentage overlap: 98%, downloading product\n",
      "Downloading S3A_OL_1_EFR____20220625T083644_20220625T083944_20220626T124836_0179_087_007_1980_MAR_O_NT_002.SEN3.zip.\n",
      "Download of product S3A_OL_1_EFR____20220625T083644_20220625T083944_20220626T124836_0179_087_007_1980_MAR_O_NT_002.SEN3.zip finished.\n",
      "Unzipping of product /Users/benloveday/Code/Git_Reps/CMTS/internal/sensors/learn-olci/2_OLCI_advanced/products/S3A_OL_1_EFR____20220625T083644_20220625T083944_20220626T124836_0179_087_007_1980_MAR_O_NT_002.SEN3.zip finished.\n",
      "Percentage overlap: 100%, downloading product\n",
      "Downloading S3A_OL_1_EFR____20220624T090255_20220624T090555_20220625T133304_0179_086_378_1980_MAR_O_NT_002.SEN3.zip.\n",
      "Download of product S3A_OL_1_EFR____20220624T090255_20220624T090555_20220625T133304_0179_086_378_1980_MAR_O_NT_002.SEN3.zip finished.\n",
      "Unzipping of product /Users/benloveday/Code/Git_Reps/CMTS/internal/sensors/learn-olci/2_OLCI_advanced/products/S3A_OL_1_EFR____20220624T090255_20220624T090555_20220625T133304_0179_086_378_1980_MAR_O_NT_002.SEN3.zip finished.\n"
     ]
    }
   ],
   "source": [
    "# 1. set up the product loop\n",
    "for final_product in final_products:\n",
    "    \n",
    "    # 2. this reads the XML into memory and finds the correct part for the polygon and compares against our reference\n",
    "    for entry in final_product.entries:\n",
    "        if 'xfdumanifest.xml' in entry:\n",
    "            with final_product.open(entry=entry) as fsrc:\n",
    "                tree = ET.ElementTree(ET.fromstring(fsrc.data))\n",
    "                root = tree.getroot()\n",
    "                polygon = np.asarray(root.findall('.//gml:posList',\n",
    "                    {'gml':\"http://www.opengis.net/gml\"})[0].text.split(' ')).astype(float)\n",
    "                this_polygon = geometry.Polygon(list(zip(polygon[1::2], polygon[0::2])))\n",
    "                pc_overlap = ROI_WKT.intersection(this_polygon).area/ROI_WKT.area*100\n",
    "\n",
    "    # 3. if our overlap is greater than the threshold, we get the download the data and unzip it\n",
    "    if pc_overlap > overlap_threshold:\n",
    "        print(f\"Percentage overlap: {int(pc_overlap)}%, downloading product\")\n",
    "\n",
    "        # download the zip file\n",
    "        with final_product.open() as fsrc, open(os.path.join(download_dir, fsrc.name), mode='wb') as fdst:\n",
    "            print(f'Downloading {fsrc.name}.')\n",
    "            shutil.copyfileobj(fsrc, fdst)\n",
    "            print(f'Download of product {fsrc.name} finished.')\n",
    "\n",
    "        # unzip the file\n",
    "        with zipfile.ZipFile(fdst.name, 'r') as zip_ref:\n",
    "            for file in zip_ref.namelist():\n",
    "                if file.startswith(str(final_product)):\n",
    "                    zip_ref.extract(file, download_dir)\n",
    "            print(f'Unzipping of product {fdst.name} finished.')\n",
    "\n",
    "        # clean up\n",
    "        os.remove(fdst.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If all went well, your products are now downloaded. You can find them in the `products` directory in the same folder as this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "### Challenge:\n",
    "\n",
    "Now you have run this for acquiring the OLCI L1 full resolution (EFR) data, can you do adapt the script above to get the corresponding granules for the OLCI L2 full resolution (WFR) granules?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"../Index.ipynb\" target=\"_blank\"><< Index</a>\n",
    "<br>\n",
    "<a href=\"./2_1_OLCI_advanced_data_access_eumdac.ipynb\" target=\"_blank\"><< Advanced OLCI data access with the EUMDAC client</a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a href=\"./2_3_OLCI_SNAP_batch_processing_C2RCC.ipynb\" target=\"_blank\">Using SNAP to batch process OLCI with C2RCC >></a>\n",
    "<hr>\n",
    "<a href=\"https://gitlab.eumetsat.int/eumetlab/ocean\" target=\"_blank\">View on GitLab</a> | <a href=\"https://training.eumetsat.int/\" target=\"_blank\">EUMETSAT Training</a> | <a href=mailto:ops@eumetsat.int target=\"_blank\">Contact helpdesk for support </a> | <a href=mailto:Copernicus.training@eumetsat.int target=\"_blank\">Contact our training team to collaborate on and reuse this material</a></span></p>"
   ]
  }
 ],
 "metadata": {
  "author": "Ben Loveday, Hayley Evers-King",
  "description": "This Jupyter Notebook shows how to access a time series Sentinel-3 Ocean and Land Colour Instrument (OLCI) data via the EUMETSAT Data Store.",
  "image": "../img/thumbs/2_2_acquire_OLCI_time_series_thumb.png",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "services": {
   "eumetsat": {
    "binder": {
     "link": "https://mybinder.org/v2/git/https%3A%2F%2Fgitlab.eumetsat.int%2Feumetlab%2Foceans%2Focean-training%2Fsensors%2Flearn-olci/HEAD?urlpath=%2Ftree%2F2_OLCI_advanced%2F2_2_acquire_OLCI_time_series.ipynb",
     "service_contact": "ops@eumetsat.int",
     "service_provider": "EUMETSAT"
    },
    "git": {
     "link": "https://gitlab.eumetsat.int/eumetlab/oceans/ocean-training/sensors/learn-olci/-/blob/main/2_OLCI_advanced/2_2_acquire_OLCI_time_series.ipynb",
     "service_contact": "ops@eumetsat.int",
     "service_provider": "EUMETSAT"
    }
   },
   "wekeo": {
    "git": {
     "link": "",
     "service_contact": "ops@eumetsat.int",
     "service_provider": "EUMETSAT"
    },
    "url": {
     "link": "",
     "service_contact": "ops@eumetsat.int",
     "service_provider": "EUMETSAT"
    }
   }
  },
  "tags": {
   "domain": "Marine",
   "platform": [
    "Sentinel-3"
   ],
   "sensor": "OLCI",
   "service": "EUMETSAT",
   "subtheme": [
    "Ocean biogeochemistry",
    "Water quality",
    "Ocean fluxes"
   ],
   "tags": [
    "Top-of-atmosphere radiance",
    "Water leaving reflectance",
    "Chlorophyll concentration",
    "Photosynthetically active radiation",
    "Diffuse attentuation coefficient",
    "Coloured dissolved organic matter absorption coefficient",
    "Total suspended matter concentration",
    "Ocean colour"
   ]
  },
  "title": "Accessing a time series of Sentinel-3 OLCI data via the EUMETSAT Data Store"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
