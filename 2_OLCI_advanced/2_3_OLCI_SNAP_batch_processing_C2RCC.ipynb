{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://gitlab.eumetsat.int/eumetlab/oceans/ocean-training/tools/frameworks/-/raw/main/img/Standard_banner.png' align='right' width='100%'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"../Index.ipynb\" target=\"_blank\"><< Index</a>\n",
    "<br>\n",
    "<a href=\"./2_2_acquire_OLCI_time_series.ipynb\" target=\"_blank\"><< Acquiring a regional OLCI times series</a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a href=\"./2_4_OLCI_SNAP_batch_processing_subset_reproj_flag_CHL.ipynb\" target=\"_blank\">Using SNAP to batch process OLCI subsetting and reprojection >></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"#138D75\">**Copernicus Marine Training Service**</font> <br>\n",
    "**Copyright:** 2023 EUMETSAT <br>\n",
    "**License:** MIT <br>\n",
    "**Authors:** Ben Loveday (EUMETSAT/Innoflair UG), Hayley Evers-King (EUMETSAT), Ana Ruescas (Brockmann Consult GmbH / University of Valencia)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<h3>Learn OLCI: Advanced</h3></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    \n",
    "<b>PREREQUISITES </b>\n",
    "        \n",
    "This notebook has the following pre-requisites:\n",
    "\n",
    "- **<a href=\"../2_OLCI_advanced/2_2_acquire_OLCI_time_series.ipynb\">2_2_acquire_OLCI_time_series.ipynb</a>** will download the example data you need to run this notebook.\n",
    "- You will also need to install the **<a href=\"https://step.esa.int/main/download/snap-download/\" target=\"_blank\">ESA SNAP package</a>**, which provides the Graph Processing Tool (GPT)\n",
    "</div>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.3 OLCI batch-processing C2RCC with SNAP\n",
    "\n",
    "### Data used\n",
    "\n",
    "| Product Description | Data Store collection ID| Product Navigator |\n",
    "|:--------------------:|:-----------------------:|:-------------:|\n",
    "| Sentinel-3 OLCI level-1B full resolution | EO:EUM:DAT:0409 | <a href=\"https://navigator.eumetsat.int/product/EO:EUM:DAT:SENTINEL-3:OL_1_EFR___NTC?query=OLCI&filter=satellite__Sentinel-3&filter=instrument__OLCI&filter=processingLevel__Level%201%20Data&s=advanced\" target=\"_blank\">link</a> |\n",
    "\n",
    "### Learning outcomes\n",
    "\n",
    "At the end of this notebook you will know;\n",
    "* How to add <font color=\"#138D75\">**plugins**</font> to SNAP\n",
    "* How to create a <font color=\"#138D75\">**SNAP GPT**</font> XML graph\n",
    "* How to <font color=\"#138D75\">**batch process**</font>  OLCI imagery using this graph\n",
    "\n",
    "### Outline\n",
    "\n",
    "The **<a href=\"https://step.esa.int/main/download/snap-download/\" target=\"_blank\">ESA SNAP package</a>** package is an excellent tool for working with both Sentinel-3 OLCI and SLSTR marine data, as well as products from many other satellites (e.g. Sentinel-1, Sentinel-2, MERIS etc.). While SNAP offers extensive capability through its Graphical User Interface (GUI), it also allows users to construct processing chains, called **graphs**. These graphs, which are written in XML, can be built in the GUI and then called from the command line. By using place-holder variables, they can then be applied to any number of images, allowing users automated processing.\n",
    "\n",
    "Here, we will show how these graphs are constructed, focussing on processing OLCI Level-1B images to Level-2 using the **<a href=\"https://www.brockmann-consult.de/wp-content/uploads/2017/11/sco1_12brockmann.pdf\n",
    "\" target=\"_blank\">C2RCC</a>** atmospheric correction and complex water retrieval processor and implementing flagging with the **<a href=\"https://www.brockmann-consult.de/portfolio/idepix/\" target=\"_blank\">IdePix</a>** multi-sensor pixel identification tool. As standard, OLCI level-2 marine products contain the geophysical parameters generated by the C2RCC processor (e.g. CHL_NN, TSM_NN), but they do not contain the reflectances. The graph we create will generate these reflectances, allowing different retrieval algorithms to be applied in complex waters, and flag the output appropriately using the quality flags provided by both the C2RCC processor and IdePix.\n",
    "\n",
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "\n",
    "## <a id='TOC_TOP'></a>Contents\n",
    "\n",
    "</div>\n",
    "    \n",
    "1. [Section 1: Adding plugins to SNAP](#section1)\n",
    "1. [Section 2: Building graphs in SNAP](#section2)\n",
    "1. [Section 3: Running a graph using GPT](#section3)\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os           # a library that allows us access to basic operating system commands like making directories\n",
    "import shutil       # a library that allows us access to basic operating system commands like copy\n",
    "import subprocess   # a library that lets us call external processes\n",
    "import fnmatch      # a library that supports comparing files to a specified pattern\n",
    "import platform     # a library that determines the current operating system\n",
    "from shapely import geometry # a library that support construction of geometry objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will create an output directory to store the products we generate in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = os.path.join(os.getcwd(), \"outputs\")\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "\n",
    "## <a id='section1'></a>Section 1: Adding plugins to SNAP\n",
    "[Back to top](#TOC_TOP)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the C2RCC processor is included in the core of the SNAP Sentinel-3 toolbox, we need to add the IdePix OLCI plugin in order to take advantage of its capability. Plugins are easily added to SNAP using the **Tools > Plugins** menu option and selecting the **IdePix OLCI** item from the **Available Plugins** menu, as shown below.\n",
    "\n",
    "*Note: SNAP has many plugins that provide additional processing options for different instruments, and we recommend that you review the catalogue to see what is available. Advanced developers may also write and contribute their own plugins to the catalogue.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../img/SNAP_plugins.png' align='centre' width='100%'></img>\n",
    "<center>Figure 1: Adding the IdePix plugin to SNAP.</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "\n",
    "## <a id='section1'></a>Section 2: Building graphs in SNAP\n",
    "[Back to top](#TOC_TOP)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Graph Builder tool can be accessed via the SNAP toolbar as shown below. This will open a new Graph Builder window that can be used to construct graphs. By default the new window will only contain **Read** and **Write** boxes. New boxes can be added by right clcking on the window and adding the required operator from the drop-down menu that appears. One the operators in place they can be connected by hovering the edge of a box, which will make a red arrow appear, and dragging the arrow to the border of the relevant next process. Once the boxes are connected (as shown in the picture), the parameters for each operator can be adapted in the tabs relevant tabs in the bottom panel. Once you are happy with a graph you can save it using the **File > Save Graph** option, or view it using the **File > View Graph XML** option.\n",
    "\n",
    "*Note: the more complex the graph, the slower the connectivity will become as SNAP must check the parameter space to see if your processing is valid*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../img/SNAP_graphbuilder.png' align='centre' width='100%'></img>\n",
    "<center>Figure 2: Building workflow \"Graphs\" in SNAP.</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graph template we will use for this processing is called **GPT_config_template_subset_idepix_c2rcc.xml**, and is saved in the same directory as this notebook. It has the following structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../img/SNAP_graphbuilder2.png' align='centre' width='50%'></img>\n",
    "<center>Figure 3: SNAP C2RCC / IdePix graphs.</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we open the XML file in a text editor, we can see the various sections that correspond to each part of the processing, as well as the places where we have defined \"place holder\" variables, which we will adapt on the fly in our batch processing. An example of this is shown below.\n",
    "\n",
    "*Note: You can request more information on each of the sections in this graph using GPT. e.g. `gpt -h c2rcc.olci`. For general help on GPT you can run `gpt -h`*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../img/SNAP_graph_XML.png' align='centre' width='100%'></img>\n",
    "<center>Figure 4: Example SNAP graph XML template with placeholders.</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "\n",
    "## <a id='section2'></a>Section 2: Running a graph using GPT\n",
    "[Back to top](#TOC_TOP)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we run our graph, we have to do four things;\n",
    "* tell our script where the GPT template we are going to run is\n",
    "* find our products of interest\n",
    "* tell our script where our GPT executable is\n",
    "* define a region of interest to run the processing over"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our template script is easy to find, as it is in the current directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "template_xml = 'GPT_config_template_subset_idepix_c2rcc.xml'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the products directory (where we downloaded our data to when we ran the prerequisite notebook **<a href=\"../2_OLCI_advanced/2_2_acquire_OLCI_time_series.ipynb\">2_2_acquire_OLCI_time_series.ipynb</a>**) as the input directory, and then collect the files that it contains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = os.path.join(os.getcwd(),'products')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/benloveday/Code/Git_Reps/CMTS/internal/sensors/learn-olci/2_OLCI_advanced/products/S3A_OL_1_EFR____20220627T092522_20220627T092822_20220630T140909_0179_087_036_1980_MAR_O_NT_002.SEN3/xfdumanifest.xml\n",
      "/Users/benloveday/Code/Git_Reps/CMTS/internal/sensors/learn-olci/2_OLCI_advanced/products/S3A_OL_1_EFR____20220628T085911_20220628T090211_20220629T160353_0180_087_050_1980_MAR_O_NT_002.SEN3/xfdumanifest.xml\n",
      "/Users/benloveday/Code/Git_Reps/CMTS/internal/sensors/learn-olci/2_OLCI_advanced/products/S3A_OL_1_EFR____20220626T095133_20220626T095433_20220627T152906_0179_087_022_1980_MAR_O_NT_002.SEN3/xfdumanifest.xml\n",
      "/Users/benloveday/Code/Git_Reps/CMTS/internal/sensors/learn-olci/2_OLCI_advanced/products/S3A_OL_1_EFR____20220624T090255_20220624T090555_20220625T133304_0179_086_378_1980_MAR_O_NT_002.SEN3/xfdumanifest.xml\n",
      "/Users/benloveday/Code/Git_Reps/CMTS/internal/sensors/learn-olci/2_OLCI_advanced/products/S3A_OL_1_EFR____20220625T083644_20220625T083944_20220626T124836_0179_087_007_1980_MAR_O_NT_002.SEN3/xfdumanifest.xml\n"
     ]
    }
   ],
   "source": [
    " # make a list of all the input files in your input directory\n",
    "input_files=[]\n",
    "for root, _, filenames in os.walk(input_dir):\n",
    "    for filename in fnmatch.filter(filenames, '*xfdumanifest.xml'):\n",
    "        if \"EFR\" in root:\n",
    "            input_files.append(os.path.join(root, filename))\n",
    "\n",
    "# and show the list        \n",
    "for input_file in input_files:\n",
    "    print(input_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we must tell our notebook where the GPT application is. The box below will set the path depending on the system default. However, if you changed the installation path when you set up SNAP, then you will need to adapt the box below to point to you GPT executable. This is called either `gpt.exe` (Windows) or just `gpt` (OSx/Linux)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This platform is: darwin\n",
      "The default path is /Applications/snap/bin/gpt, please adapt the GPT_PATH variable if this is not correct\n"
     ]
    }
   ],
   "source": [
    "print(f\"This platform is: {platform.system().lower()}\")\n",
    "if platform.system().lower() == \"darwin\":\n",
    "    GPT_PATH = os.path.join(\"/\", \"Applications\", \"snap\", \"bin\", \"gpt\")\n",
    "elif platform.system().lower() == \"windows\":\n",
    "    GPT_PATH = os.path.join(\"C:/\", \"Users\", \"ysamuel\", \"AppData\", \"local\", \"Programs\", \"snap\", \"bin\", \"gpt.exe\")\n",
    "print(f\"The default path is {GPT_PATH}, please adapt the GPT_PATH variable if this is not correct\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we will define a region of interest (ROI). This is not strictly necessary and we don't define and ROI SNAP/GPT will process the entire granule. However, this can take quite some time and usually, as users, we are looking at a specific area, so we will define on in our example. We define our ROI as an area to the North East of Gottland, in the Baltic Sea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set geo_region to subset\n",
    "# space/time filter the collection for products\n",
    "north = 59.25\n",
    "west = 18.50\n",
    "south = 56.75\n",
    "east = 21.50\n",
    "\n",
    "ROI = [[west, south], [east, south], [east, north], [west, north], [west, south]]\n",
    "ROI_polygon = geometry.Polygon([[p[0], p[1]] for p in ROI])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have set all of our parameters, we start the main part of our code, where we call GPT to process this L1 data. The code will loop through each of our granules and perform the following tasks:\n",
    "\n",
    "1. define the output file name, using the input file name and our specified output directory\n",
    "2. copy the template xml to a new config for this granule, and customise it by replacing the placeholders\n",
    "3. build and call the gpt command using the python subprocess module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------- Processing: --------------\n",
      "/Users/benloveday/Code/Git_Reps/CMTS/internal/sensors/learn-olci/2_OLCI_advanced/products/S3A_OL_1_EFR____20220627T092522_20220627T092822_20220630T140909_0179_087_036_1980_MAR_O_NT_002.SEN3/xfdumanifest.xml\n",
      "-- To: --\n",
      "S3A_OL_1_EFR____20220627T092522_20220627T092822_20220630T140909_0179_087_036_1980_MAR_O_NT_002_SUBSET_IDEPIX_C2RCC.nc\n",
      "-- Generating config: --\n",
      "/Users/benloveday/Code/Git_Reps/CMTS/internal/sensors/learn-olci/2_OLCI_advanced/outputs/run_config.xml\n",
      "-- Config ready; running: --\n",
      "/Applications/snap/bin/gpt /Users/benloveday/Code/Git_Reps/CMTS/internal/sensors/learn-olci/2_OLCI_advanced/outputs/run_config.xml\n",
      "----- Finished running this product -----\n",
      "\n",
      "-------------- Processing: --------------\n",
      "/Users/benloveday/Code/Git_Reps/CMTS/internal/sensors/learn-olci/2_OLCI_advanced/products/S3A_OL_1_EFR____20220628T085911_20220628T090211_20220629T160353_0180_087_050_1980_MAR_O_NT_002.SEN3/xfdumanifest.xml\n",
      "-- To: --\n",
      "S3A_OL_1_EFR____20220628T085911_20220628T090211_20220629T160353_0180_087_050_1980_MAR_O_NT_002_SUBSET_IDEPIX_C2RCC.nc\n",
      "-- Generating config: --\n",
      "/Users/benloveday/Code/Git_Reps/CMTS/internal/sensors/learn-olci/2_OLCI_advanced/outputs/run_config.xml\n",
      "-- Config ready; running: --\n",
      "/Applications/snap/bin/gpt /Users/benloveday/Code/Git_Reps/CMTS/internal/sensors/learn-olci/2_OLCI_advanced/outputs/run_config.xml\n",
      "----- Finished running this product -----\n",
      "\n",
      "-------------- Processing: --------------\n",
      "/Users/benloveday/Code/Git_Reps/CMTS/internal/sensors/learn-olci/2_OLCI_advanced/products/S3A_OL_1_EFR____20220626T095133_20220626T095433_20220627T152906_0179_087_022_1980_MAR_O_NT_002.SEN3/xfdumanifest.xml\n",
      "-- To: --\n",
      "S3A_OL_1_EFR____20220626T095133_20220626T095433_20220627T152906_0179_087_022_1980_MAR_O_NT_002_SUBSET_IDEPIX_C2RCC.nc\n",
      "-- Generating config: --\n",
      "/Users/benloveday/Code/Git_Reps/CMTS/internal/sensors/learn-olci/2_OLCI_advanced/outputs/run_config.xml\n",
      "-- Config ready; running: --\n",
      "/Applications/snap/bin/gpt /Users/benloveday/Code/Git_Reps/CMTS/internal/sensors/learn-olci/2_OLCI_advanced/outputs/run_config.xml\n",
      "----- Finished running this product -----\n",
      "\n",
      "-------------- Processing: --------------\n",
      "/Users/benloveday/Code/Git_Reps/CMTS/internal/sensors/learn-olci/2_OLCI_advanced/products/S3A_OL_1_EFR____20220624T090255_20220624T090555_20220625T133304_0179_086_378_1980_MAR_O_NT_002.SEN3/xfdumanifest.xml\n",
      "-- To: --\n",
      "S3A_OL_1_EFR____20220624T090255_20220624T090555_20220625T133304_0179_086_378_1980_MAR_O_NT_002_SUBSET_IDEPIX_C2RCC.nc\n",
      "-- Generating config: --\n",
      "/Users/benloveday/Code/Git_Reps/CMTS/internal/sensors/learn-olci/2_OLCI_advanced/outputs/run_config.xml\n",
      "-- Config ready; running: --\n",
      "/Applications/snap/bin/gpt /Users/benloveday/Code/Git_Reps/CMTS/internal/sensors/learn-olci/2_OLCI_advanced/outputs/run_config.xml\n",
      "----- Finished running this product -----\n",
      "\n",
      "-------------- Processing: --------------\n",
      "/Users/benloveday/Code/Git_Reps/CMTS/internal/sensors/learn-olci/2_OLCI_advanced/products/S3A_OL_1_EFR____20220625T083644_20220625T083944_20220626T124836_0179_087_007_1980_MAR_O_NT_002.SEN3/xfdumanifest.xml\n",
      "-- To: --\n",
      "S3A_OL_1_EFR____20220625T083644_20220625T083944_20220626T124836_0179_087_007_1980_MAR_O_NT_002_SUBSET_IDEPIX_C2RCC.nc\n",
      "-- Generating config: --\n",
      "/Users/benloveday/Code/Git_Reps/CMTS/internal/sensors/learn-olci/2_OLCI_advanced/outputs/run_config.xml\n",
      "-- Config ready; running: --\n",
      "/Applications/snap/bin/gpt /Users/benloveday/Code/Git_Reps/CMTS/internal/sensors/learn-olci/2_OLCI_advanced/outputs/run_config.xml\n",
      "----- Finished running this product -----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# MAIN: the loop goes over each input file in the input_files list\n",
    "for input_file in input_files:\n",
    "\n",
    "    # 1. define an output file name. This is derived from the input file, but with a _SUBSET_IDEPIX_C2RCC suffix.\n",
    "    output_file = input_file.replace(input_dir,output_dir)\n",
    "    output_file = os.path.dirname(output_file).replace('.SEN3','_SUBSET_IDEPIX_C2RCC.nc')\n",
    "    print(f\"-------------- Processing: --------------\\n{input_file}\")\n",
    "    print(f\"-- To: --\\n{os.path.basename(output_file)}\")\n",
    "    \n",
    "    # 2. read the template xml and adapt it for the current granule\n",
    "    my_config = os.path.join(output_dir, 'run_config.xml')\n",
    "    print(f\"-- Generating config: --\\n{my_config}\")\n",
    "    shutil.copy(template_xml, my_config)\n",
    "\n",
    "    with open(template_xml, 'r') as file:\n",
    "        filedata = file.read()\n",
    "        \n",
    "    # Replace the target strings\n",
    "    filedata = filedata.replace('SOURCE_PRODUCT', input_file)\n",
    "    filedata = filedata.replace('OUTPUT_PRODUCT', output_file)\n",
    "    filedata = filedata.replace('GEO_REGION', str(ROI_polygon))\n",
    "\n",
    "    # Write the file out again\n",
    "    with open(my_config, 'w') as file:\n",
    "        file.write(filedata)\n",
    "\n",
    "    # 3. the processing call is a follows below.\n",
    "    c2rcc_processing_call = GPT_PATH + ' ' + my_config\n",
    "    \n",
    "    # It is useful to check that the command call is correct before launching the call\n",
    "    print(f\"-- Config ready; running: --\\n{c2rcc_processing_call}\")\n",
    "    \n",
    "    # Run the gpt command\n",
    "    process = subprocess.Popen(c2rcc_processing_call, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "    output, err = process.communicate()\n",
    "\n",
    "    print(f\"----- Finished running this product -----\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you check your output directory, you should now see a number of netCDF files that correspond to the input files we processed. You can open these netCDF files in SNAP to see what output you have generated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"../Index.ipynb\" target=\"_blank\"><< Index</a>\n",
    "<br>\n",
    "<a href=\"./2_2_acquire_OLCI_time_series.ipynb\" target=\"_blank\"><< Acquiring a regional OLCI times series</a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a href=\"./2_4_OLCI_SNAP_batch_processing_subset_reproj_flag_CHL.ipynb\" target=\"_blank\">Using SNAP to batch process OLCI subsetting and reprojection >></a>\n",
    "<hr>\n",
    "<a href=\"https://gitlab.eumetsat.int/eumetlab/ocean\" target=\"_blank\">View on GitLab</a> | <a href=\"https://training.eumetsat.int/\" target=\"_blank\">EUMETSAT Training</a> | <a href=mailto:ops@eumetsat.int target=\"_blank\">Contact helpdesk for support </a> | <a href=mailto:Copernicus.training@eumetsat.int target=\"_blank\">Contact our training team to collaborate on and reuse this material</a></span></p>"
   ]
  }
 ],
 "metadata": {
  "author": "Ben Loveday, Hayley Evers-King, Ana Ruescas",
  "description": "This Jupyter Notebook shows how to use the ESA STEP SNAP package to batch-process Sentinel-3 Ocean and Land Colour Instrument (OLCI) level-2 products, performing seubsetting and atmospheric correction with the Case 2 Regional Coast Colour complex water processor(C2RCC).",
  "image": "../img/thumbs/2_3_OLCI_SNAP_batch_processing_C2RCC_thumb.png",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "services": {
   "eumetsat": {
    "binder": {
     "link": "https://mybinder.org/v2/git/https%3A%2F%2Fgitlab.eumetsat.int%2Feumetlab%2Foceans%2Focean-training%2Fsensors%2Flearn-olci/HEAD?urlpath=%2Ftree%2F2_OLCI_advanced%2F2_3_OLCI_SNAP_batch_processing_C2RCC.ipynb",
     "service_contact": "ops@eumetsat.int",
     "service_provider": "EUMETSAT"
    },
    "git": {
     "link": "https://gitlab.eumetsat.int/eumetlab/oceans/ocean-training/sensors/learn-olci/-/blob/main/2_OLCI_advanced/2_3_OLCI_SNAP_batch_processing_C2RCC.ipynb",
     "service_contact": "ops@eumetsat.int",
     "service_provider": "EUMETSAT"
    }
   },
   "wekeo": {
    "git": {
     "link": "",
     "service_contact": "ops@eumetsat.int",
     "service_provider": "EUMETSAT"
    },
    "url": {
     "link": "",
     "service_contact": "ops@eumetsat.int",
     "service_provider": "EUMETSAT"
    }
   }
  },
  "tags": {
   "domain": "Marine",
   "platform": [
    "Sentinel-3"
   ],
   "sensor": "OLCI",
   "service": "EUMETSAT",
   "subtheme": [
    "Ocean biogeochemistry",
    "Water quality",
    "Ocean fluxes"
   ],
   "tags": [
    "Top-of-atmosphere radiance",
    "Water leaving reflectance",
    "Ocean colour"
   ]
  },
  "title": "Batch processing Sentinel-3 OLCI data using SNAP: Atmospheric correction with the C2RCC processor."
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
